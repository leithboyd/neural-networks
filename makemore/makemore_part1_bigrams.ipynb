{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min = 2, max = 15\n"
     ]
    }
   ],
   "source": [
    "print(f'min = {min(len(w) for w in words)}, max = {max(len(w) for w in words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s: i for i, s in enumerate(('.', *alphabet))}\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "num_classes = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chars = ['.'] + list(w) + ['.']\n",
    "    for c_curr, c_next in zip(chars, chars[1:]):\n",
    "        #print(c_curr, c_next)\n",
    "        xs.append(stoi[c_curr])\n",
    "        ys.append(stoi[c_next])\n",
    "\n",
    "xs = tf.convert_to_tensor(xs)\n",
    "ys = tf.convert_to_tensor(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = tf.one_hot(xs, num_classes)\n",
    "yidx = tf.stack([tf.range(ys.shape[0]), ys], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal((num_classes, num_classes), seed=1), name='W', trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9211085\n",
      "3.7454646\n",
      "3.599487\n",
      "3.4770389\n",
      "3.3746512\n",
      "3.2885842\n",
      "3.2153761\n",
      "3.1525435\n",
      "3.0984082\n",
      "3.0516932\n",
      "3.0113091\n",
      "2.976297\n",
      "2.945819\n",
      "2.9191573\n",
      "2.8957086\n",
      "2.8749702\n",
      "2.8565285\n",
      "2.8400426\n",
      "2.8252325\n",
      "2.8118653\n",
      "2.7997484\n",
      "2.78872\n",
      "2.778644\n",
      "2.7694056\n",
      "2.7609065\n",
      "2.7530627\n",
      "2.7458024\n",
      "2.7390623\n",
      "2.7327886\n",
      "2.7269332\n",
      "2.7214553\n",
      "2.7163174\n",
      "2.7114887\n",
      "2.7069404\n",
      "2.7026472\n",
      "2.6985881\n",
      "2.6947432\n",
      "2.6910946\n",
      "2.6876273\n",
      "2.684328\n",
      "2.681184\n",
      "2.678184\n",
      "2.6753182\n",
      "2.6725774\n",
      "2.6699538\n",
      "2.66744\n",
      "2.6650286\n",
      "2.662714\n",
      "2.6604905\n",
      "2.6583529\n",
      "2.6562965\n",
      "2.6543171\n",
      "2.65241\n",
      "2.6505725\n",
      "2.6488001\n",
      "2.6470907\n",
      "2.64544\n",
      "2.6438465\n",
      "2.6423068\n",
      "2.6408186\n",
      "2.63938\n",
      "2.6379886\n",
      "2.6366422\n",
      "2.6353393\n",
      "2.6340775\n",
      "2.6328564\n",
      "2.6316726\n",
      "2.6305258\n",
      "2.6294146\n",
      "2.628337\n",
      "2.6272924\n",
      "2.6262789\n",
      "2.625296\n",
      "2.6243422\n",
      "2.6234164\n",
      "2.622518\n",
      "2.6216452\n",
      "2.620798\n",
      "2.6199749\n",
      "2.6191754\n",
      "2.6183987\n",
      "2.6176436\n",
      "2.61691\n",
      "2.6161964\n",
      "2.6155028\n",
      "2.6148288\n",
      "2.6141727\n",
      "2.6135345\n",
      "2.6129136\n",
      "2.6123092\n",
      "2.6117215\n",
      "2.6111488\n",
      "2.6105917\n",
      "2.6100495\n",
      "2.6095214\n",
      "2.6090074\n",
      "2.6085064\n",
      "2.608018\n",
      "2.6075425\n",
      "2.6070793\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 20\n",
    "reg_strength = 0.1\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = xenc @ W\n",
    "        counts = tf.math.exp(logits)\n",
    "        probs = counts / tf.math.reduce_sum(counts, axis=1, keepdims=True)\n",
    "        loss = tf.math.reduce_mean(-tf.math.log(tf.gather_nd(probs, yidx))) + reg_strength * tf.math.reduce_mean(W**2)\n",
    "\n",
    "    print(loss.numpy())\n",
    "\n",
    "    dl_dw = tape.gradient(loss, W)\n",
    "    W.assign_sub(learning_rate*dl_dw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = tfp.distributions.Multinomial(1, probs=[0.2, 0.5, 0.3])\n",
    "dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmimaya.\n",
      "za.\n",
      "el.\n",
      "d.\n",
      "rbreka.\n",
      "mzadeja.\n",
      "kejantyn.\n",
      "jajoneixindailinda.\n",
      "laulaesjgh.\n",
      "dggowuumaqapeeianiyayn.\n"
     ]
    }
   ],
   "source": [
    "# Generate in serial\n",
    "\n",
    "n_gen = 10\n",
    "for _ in range(n_gen):\n",
    "    ienc = tf.one_hot([0], num_classes)\n",
    "    out = []\n",
    "    while True:\n",
    "        logits = ienc @ W\n",
    "        counts = tf.math.exp(logits)\n",
    "        probs = counts / tf.math.reduce_sum(counts, axis=1, keepdims=True)\n",
    "\n",
    "        ienc = tfp.distributions.Multinomial(1, probs=probs).sample()\n",
    "        i = tf.math.argmax(tf.squeeze(ienc))\n",
    "\n",
    "        out.append(itos[i.numpy()])\n",
    "\n",
    "        if i == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n",
      "pn\n",
      "e\n",
      "man\n",
      "lama\n",
      "xili\n",
      "jonnav\n",
      "ie\n",
      "gie\n",
      "drte\n",
      "trjetare\n",
      "kessgonch\n",
      "ben\n",
      "ommir\n",
      "elon\n",
      "kanl\n",
      "dozala\n",
      "manr\n",
      "caayguorealbrary\n",
      "deq\n",
      "cerikkwdetelecen\n",
      "kanabrynilere\n",
      "mamriazrykusai\n",
      "malfx\n",
      "ieleeri\n",
      "dige\n",
      "ensn\n",
      "yn\n",
      "ylvibolltizah\n",
      "loman\n",
      "dbeliyy\n",
      "jryaritlmfon\n",
      "s\n",
      "arcaxxy\n",
      "jbeleewopsar\n",
      "seolor\n",
      "zmararikcus\n",
      "srslaamgburosobory\n",
      "asianynni\n",
      "kxgribeda\n",
      "ze\n",
      "brh\n",
      "kerlan\n",
      "os\n",
      "aszxx\n",
      "k\n",
      "dwvdqle\n",
      "we\n",
      "dechistonn\n",
      "kejacbolarame\n",
      "ralesrbch\n",
      "a\n",
      "ekahamaheohiha\n",
      "in\n",
      "tailla\n",
      "ke\n",
      "losusgh\n",
      "autxi\n",
      "lezafwtoninnn\n",
      "cariebetian\n",
      "cayavariaamquacimy\n",
      "a\n",
      "friou\n",
      "rorma\n",
      "canikah\n",
      "eleisiylia\n",
      "mixthyai\n",
      "vharai\n",
      "ta\n",
      "ziarn\n",
      "tkenyadimindjayvielydenebera\n",
      "fall\n",
      "may\n",
      "ma\n",
      "r\n",
      "kg\n",
      "maidrize\n",
      "llionkamausala\n",
      "ana\n",
      "lenuhay\n",
      "zavaorblio\n",
      "bxli\n",
      "a\n",
      "s\n",
      "xgmasel\n",
      "jionikila\n",
      "mone\n",
      "cssonil\n",
      "dan\n",
      "jasiktie\n",
      "mi\n",
      "imadaroxh\n",
      "midj\n",
      "sapiyobo\n",
      "jbxm\n",
      "gvkeniy\n",
      "nen\n",
      "nauderelann\n",
      "jrfxelaxxuma\n",
      "lainiligshliele\n",
      "ina\n"
     ]
    }
   ],
   "source": [
    "# Generate in parallel, has a bias towards generating shorter examples\n",
    "\n",
    "n_parallel = 10\n",
    "n_gen = 10\n",
    "gen_count = 0\n",
    "\n",
    "ienc = tf.one_hot([0]*n_parallel, num_classes)\n",
    "out = [[] for _ in range(n_parallel)]\n",
    "\n",
    "while gen_count < n_gen:\n",
    "    logits = ienc @ W\n",
    "    counts = tf.math.exp(logits)\n",
    "    probs = counts / tf.math.reduce_sum(counts, axis=1, keepdims=True)\n",
    "\n",
    "    ienc = tfp.distributions.Multinomial(1, probs=probs).sample()\n",
    "    iz =  tf.argmax(ienc, axis=1)\n",
    "\n",
    "    for o, i in zip(out, iz):\n",
    "        if i == 0:\n",
    "            print(''.join(o))\n",
    "            o.clear()\n",
    "            gen_count += 1\n",
    "        else:\n",
    "            o.append(itos[i.numpy()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9d1ba5e4994b41d7ada9926998c000b0678c1da28b9ce02a49f5dd66c9f126b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
